{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heuristic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tournament"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach #1  -  weighted difference\n",
    "\n",
    "Rationale:\n",
    "\n",
    "Results:\n",
    "ID_Improved: 58.57%\n",
    "Student: 60.71%\n",
    "\n",
    "Code: \n",
    "<pre>\n",
    "own_moves = len(game.get_legal_moves(player))\n",
    "opp_moves = len(game.get_legal_moves(game.get_opponent(player)))\n",
    "return float(2*own_moves - 0.5*opp_moves)\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This script evaluates the performance of the custom heuristic function by\n",
      "comparing the strength of an agent using iterative deepening (ID) search with\n",
      "alpha-beta pruning against the strength rating of agents using other heuristic\n",
      "functions.  The `ID_Improved` agent provides a baseline by measuring the\n",
      "performance of a basic agent using Iterative Deepening and the \"improved\"\n",
      "heuristic (from lecture) on your hardware.  The `Student` agent then measures\n",
      "the performance of Iterative Deepening and the custom heuristic against the\n",
      "same opponents.\n",
      "\n",
      "\n",
      "*************************\n",
      " Evaluating: ID_Improved \n",
      "*************************\n",
      "\n",
      "Playing Matches:\n",
      "----------\n",
      "  Match 1: ID_Improved vs   Random    \tResult: 18 to 2\n",
      "  Match 2: ID_Improved vs   MM_Null   \tResult: 15 to 5\n",
      "  Match 3: ID_Improved vs   MM_Open   \tResult: 14 to 6\n",
      "  Match 4: ID_Improved vs MM_Improved \tResult: 10 to 10\n",
      "  Match 5: ID_Improved vs   AB_Null   \tResult: 11 to 9\n",
      "  Match 6: ID_Improved vs   AB_Open   \tResult: 8 to 12\n",
      "  Match 7: ID_Improved vs AB_Improved \tResult: 6 to 14\n",
      "\n",
      "\n",
      "Results:\n",
      "----------\n",
      "ID_Improved         58.57%\n",
      "\n",
      "*************************\n",
      "   Evaluating: Student   \n",
      "*************************\n",
      "\n",
      "Playing Matches:\n",
      "----------\n",
      "  Match 1:   Student   vs   Random    \tResult: 20 to 0\n",
      "  Match 2:   Student   vs   MM_Null   \tResult: 13 to 7\n",
      "  Match 3:   Student   vs   MM_Open   \tResult: 11 to 9\n",
      "  Match 4:   Student   vs MM_Improved \tResult: 15 to 5\n",
      "  Match 5:   Student   vs   AB_Null   \tResult: 15 to 5\n",
      "  Match 6:   Student   vs   AB_Open   \tResult: 4 to 16\n",
      "  Match 7:   Student   vs AB_Improved \tResult: 7 to 13\n",
      "\n",
      "\n",
      "Results:\n",
      "----------\n",
      "Student             60.71%\n"
     ]
    }
   ],
   "source": [
    "%run tournament.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
